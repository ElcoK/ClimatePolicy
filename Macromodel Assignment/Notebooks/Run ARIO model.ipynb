{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path= '..'\n",
    "\n",
    "from indirect import run_model\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = sys.float_info.epsilon  # smallest possible difference\n",
    "\n",
    "def get_recon_curve(ini_curve,timesteps):\n",
    "    if timesteps == 0:\n",
    "        return [0,0]\n",
    "\n",
    "    def interpolate(inp, fi):\n",
    "        i = int(fi)\n",
    "        f = fi - i\n",
    "        return (inp[i] if f < EPSILON else\n",
    "                inp[i] + f*(inp[i+1]-inp[i]))\n",
    "\n",
    "    inp = ini_curve\n",
    "    new_len = timesteps\n",
    "\n",
    "    delta = (len(inp)-1) / float(new_len-1)\n",
    "    outp = np.diff([1-int(interpolate(inp, i*delta))/100 for i in range(new_len)])\n",
    "    #outp = [1-int(interpolate(inp, i*delta))/100 for i in range(new_len)]\n",
    "    return list(outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IO_TABLE = pd.read_csv(os.path.join(data_path,'data','Rijnmond_IO.csv'),index_col=[0],header=[0])\n",
    "SECTORS = list(IO_TABLE[:25].index.get_level_values(0).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load direct impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run economic impact model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scenarios = list(direct_impacts.index.get_level_values(0).unique())\n",
    "diff_recons_tot = {}\n",
    "diff_recons_ind = {}\n",
    "curve_types = ['linear','convex','concave']\n",
    "concave = np.array([100,98,93,88,83,75,64,53,38,20,0])\n",
    "linear = np.array([100,90,80,70,60,50,40,30,20,10,0])\n",
    "convex = np.array([100,70,55,40,30,20,15,10,5,0,0])\n",
    "\n",
    "for recon_type,curve_type in zip([linear,convex,concave],curve_types): #\n",
    "       \n",
    "    get_losses_tot = {}\n",
    "    get_losses_ind = {}\n",
    "\n",
    "    for scen, new_df in tqdm(direct_impacts.groupby(level=0),total=len(direct_impacts.groupby(level=0))):\n",
    "        # create reconstruction matrix\n",
    "        all_sectors = [get_recon_curve(recon_type,int(x)) for x in list(JustFlood[(int(scen.split('_')[0][1:]),int(scen.split('_')[1]))])]\n",
    "        pad = max(len(max(all_sectors, key=len))+1,180)\n",
    "        recon_matrix = np.array([i + [0]*(pad-len(i)) for i in all_sectors])\n",
    "\n",
    "        # perform calculations\n",
    "        new_df = new_df.copy()\n",
    "        new_df.loc[new_df.rel_m2_inun > 1] = 0.99\n",
    "        ratio_df = new_df.merge(corr_df.reset_index(),left_on='landuse',right_on='index')\n",
    "        rel_impact = dict(zip(ratio_df.landuse,ratio_df.rel_m2_inun*ratio_df.ratio))\n",
    "        \n",
    "        get_losses_tot[scen] = (run_model([rel_impact[x] if x in rel_impact.keys() else 0 for x in SECTORS],recon_matrix,3,pad,dict(direct_damages[scen])))[0]\n",
    "        get_losses_ind[scen] = (run_model([rel_impact[x] if x in rel_impact.keys() else 0 for x in SECTORS],recon_matrix,3,pad,dict(direct_damages[scen])))[1]\n",
    "\n",
    "    df_tot = pd.DataFrame.from_dict(get_losses_tot,orient='index')\n",
    "    df_tot.index = pd.MultiIndex.from_tuples([x.split('_')[0:2] for x in scenarios])\n",
    "    df_tot = df_tot.unstack(0)\n",
    "    df_tot.index = df_tot.index.astype(int)\n",
    "    df_tot = df_tot.sort_index()\n",
    "    df_tot.columns = df_tot.columns.droplevel(0)\n",
    "    diff_recons_tot[curve_type] = df_tot\n",
    "\n",
    "    df_ind =  pd.DataFrame.from_dict(get_losses_ind,orient='index',columns=SECTORS)\n",
    "    df_ind.index = pd.MultiIndex.from_tuples([x.split('_')[0:2] for x in scenarios])\n",
    "    df_ind = df_ind.unstack(0)\n",
    "    df_ind.index = df_ind.index.astype(int)\n",
    "    df_ind = df_ind.sort_index()\n",
    "    diff_recons_ind[curve_type] = df_ind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
